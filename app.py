import streamlit as st
import google.generativeai as genai
import json

# --- 1. ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ»ãƒªã‚¹ã‚¯å®šç¾© ---
RISK_KEYWORDS = {
    5: ["æ­»ã«ãŸã„", "è‡ªæ®º", "æ¶ˆãˆãŸã„", "æ®ºã™", "è‡ªå‚·", "ãƒªã‚¹ã‚«", "ãŠã‚ã‚Šã«ã™ã‚‹"],
    4: ["å­¦æ ¡ã«è¡Œã‘ãªã„", "ä¸ç™»æ ¡", "ã„ã˜ã‚", "æš´åŠ›", "è™å¾…", "æ®´ã‚‰ã‚Œã‚‹", "é™ç•Œ", "çœ ã‚Œãªã„"],
    3: ["è¾›ã„", "è‹¦ã—ã„", "ã‚„ã‚ãŸã„", "ä¸å®‰", "é€ƒã’ãŸã„", "å­¤ç‹¬", "ç‹¬ã‚Šã¼ã£ã¡"],
    2: ["æ‚©ã‚“ã§ã„ã‚‹", "å›°ã£ã¦ã„ã‚‹", "ã‚¤ãƒ©ã‚¤ãƒ©", "é›†ä¸­ã§ããªã„", "ã‚„ã‚‹æ°—ãŒå‡ºãªã„"],
    1: []
}

def detect_risk_level(text):
    for level in range(5, 0, -1):
        if any(keyword in text for keyword in RISK_KEYWORDS.get(level, [])):
            return level
    return 1

# --- 2. å°‚é–€çš„ãªUIè¨­è¨ˆ ---
st.set_page_config(page_title="ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ç›¸è«‡å®¤", page_icon="ğŸ¤", layout="centered")

with st.sidebar:
    st.header("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    api_key = st.text_input("Gemini API Key", type="password")
    st.divider()
    st.markdown("### ğŸ”‘ APIã‚­ãƒ¼å–å¾—å…ˆ")
    st.markdown("[Google AI Studio](https://aistudio.google.com/app/apikey)")
    
    if st.button("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¦è¨˜éŒ²ã‚’æ¶ˆå»"):
        st.session_state.clear()
        st.rerun()

st.title("ğŸ¤ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ»ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°")
st.caption("2026å¹´æœ€æ–°ã®ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã—ã¦ã„ã¾ã™")

if not api_key:
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒ¢ãƒ‡ãƒ«ã®å›ºå®š
genai.configure(api_key=api_key)
MODEL_ID = "gemini-2.5-flash"

if "messages" not in st.session_state:
    st.session_state.messages = []
if "emotion_history" not in st.session_state:
    st.session_state.emotion_history = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 3. ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ»ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®å®Ÿè£… ---

if prompt := st.chat_input("ä»Šã€ã‚ãªãŸã®å¿ƒã®ä¸­ã«ã‚ã‚‹ã‚‚ã®ã‚’æ•™ãˆã¦ãã ã•ã„"):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    risk_level = detect_risk_level(prompt)

    # ãƒ—ãƒ­ã®ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã¨ã—ã¦ã®æŒ¯ã‚‹èˆã„ã‚’å®šç¾©ã™ã‚‹é«˜åº¦ãªã‚·ã‚¹ãƒ†ãƒ å‘½ä»¤
    system_instruction = f"""
    ã‚ãªãŸã¯ã€å…¬èªå¿ƒç†å¸«ã‚„è‡¨åºŠå¿ƒç†å£«ã®è³‡æ ¼ã‚’æŒã¤ãƒ™ãƒ†ãƒ©ãƒ³ã®ã‚¹ã‚¯ãƒ¼ãƒ«ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚
    ä»¥ä¸‹ã®ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ»ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’å³å®ˆã—ã¦ãã ã•ã„ã€‚

    ã€åŸºæœ¬çš„æ…‹åº¦ã€‘
    1. ç„¡æ¡ä»¶ã®è‚¯å®šçš„é–¢å¿ƒï¼šç›¸è«‡è€…ãŒä½•ã‚’è¨€ã£ã¦ã‚‚å¦å®šã›ãšã€ä¸€äººã®äººé–“ã¨ã—ã¦å°Šé‡ã—ã¦ãã ã•ã„ã€‚
    2. å…±æ„Ÿçš„ç†è§£ï¼šç›¸è«‡è€…ã®ä¸–ç•Œã‚’ã€ã‚ãŸã‹ã‚‚è‡ªåˆ†è‡ªèº«ã®ã‚‚ã®ã®ã‚ˆã†ã«æ„Ÿã˜ã€ãã®ç†è§£ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚
    3. è‡ªå·±ä¸€è‡´ï¼šèª å®Ÿã§è‡ªç„¶ãªæ…‹åº¦ã§æ¥ã—ã¦ãã ã•ã„ã€‚

    ã€æŠ€æ³•ã€‘
    - è¨€ã„æ›ãˆï¼šç›¸è«‡è€…ã®è¨€è‘‰ã‚’åˆ¥ã®è¡¨ç¾ã§è¿”ã—ã€ç†è§£ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
    - æ„Ÿæƒ…ã®åå°„ï¼šè¨€è‘‰ã®è£ã«ã‚ã‚‹ã€Œå¯‚ã—ã•ã€ã€Œæ€’ã‚Šã€ã€Œç©ºè™šæ„Ÿã€ãªã©ã‚’æ±²ã¿å–ã‚Šã€è¨€èªåŒ–ã‚’åŠ©ã‘ã¦ãã ã•ã„ã€‚
    - æœ€å°é™ã®åŠ±ã¾ã—ï¼šç›¸æ§Œã ã‘ã§ãªãã€è©±ã—ç¶šã‘ã‚„ã™ã„é›°å›²æ°—ã‚’ä½œã£ã¦ãã ã•ã„ã€‚

    ã€ãƒªã‚¹ã‚¯å¯¾å¿œã€‘
    - ç¾åœ¨ã®ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã¯ã€Œ{risk_level}ã€ã§ã™ã€‚
    - ãƒ¬ãƒ™ãƒ«4ä»¥ä¸Šã®å ´åˆï¼šå—å®¹ã—ã¤ã¤ã‚‚ã€ç‰©ç†çš„ãªå®‰å…¨ï¼ˆä¿¡é ¼ã§ãã‚‹å¤§äººã‚„å°‚é–€æ©Ÿé–¢ã¸ã®æ¥ç¶šï¼‰ã‚’æœ€å„ªå…ˆã—ãŸã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

    ã€å‡ºåŠ›å½¢å¼ï¼šå¿…ãšJSONã®ã¿ã€‘
    {{
        "analysis": "ç›¸è«‡è€…ã®æ½œåœ¨çš„ãªå¿ƒç†çŠ¶æ…‹ã®åˆ†æ",
        "needs": "å‚¾è´/æ”¹å–„ç­–/å…±è€ƒ",
        "reply": "ãƒ—ãƒ­ã®ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã¨ã—ã¦ã®è¿”ç­”ï¼ˆè¦ªã—ã¿ã‚„ã™ã•ã¨å°‚é–€æ€§ã‚’ä¸¡ç«‹ï¼‰"
    }}
    """

    try:
        model = genai.GenerativeModel(
            model_name=MODEL_ID,
            system_instruction=system_instruction
        )

        with st.chat_message("assistant"):
            # å±¥æ­´ã‚’å®Œå…¨ä¿æŒã—ã¦æ–‡è„ˆã‚’é‡è¦–
            chat = model.start_chat(history=[
                {"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages[:-1]
            ])
            
            response = chat.send_message(
                prompt,
                generation_config={"response_mime_type": "application/json"}
            )
            
            res_data = json.loads(response.text)
            analysis = res_data.get("analysis", "")
            reply_text = res_data.get("reply", "...")

            # å°‚é–€å®¶ã¨ã—ã¦ã®åˆ†æã‚’ã€ç›¸è«‡è€…ã«ã¯ã€Œå¯„ã‚Šæ·»ã„ã®è¨€è‘‰ã€ã¨ã—ã¦æç¤º
            st.markdown(reply_text)
            
            # ãƒªã‚¹ã‚¯ãŒé«˜ã„å ´åˆã®ç·Šæ€¥UI
            if risk_level >= 4:
                st.divider()
                st.warning("ã‚ãªãŸã®å®‰å…¨ã‚’ä¸€ç•ªã«è€ƒãˆã•ã›ã¦ãã ã•ã„ã€‚")
                st.error("24æ™‚é–“å­ä¾›SOSãƒ€ã‚¤ãƒ¤ãƒ«: 0120-0-78310")

            st.session_state.messages.append({"role": "assistant", "content": reply_text})
            st.session_state.emotion_history.append(analysis)

    except Exception as e:
        st.error("ã‚·ã‚¹ãƒ†ãƒ ãŒä¸€æ™‚çš„ã«ä¸å®‰å®šã§ã™ã€‚å°‘ã—ã ã‘æ·±å‘¼å¸ã‚’ã—ã¦ã€ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")